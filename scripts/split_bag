#!/usr/bin/env python
# PYTHON_ARGCOMPLETE_OK

# A simple python script to split a large bag file into smaller ones, either by duration or size.

import argparse
import argcomplete
import os

import rosbag

def parse_arguments():
    parser = argparse.ArgumentParser(description='Split a bag file by size')
    parser.add_argument("bag", help='Bagfile to be split')
    parser.add_argument("-d", "--duration", type=int, help="Bag file duration [s]")
    parser.add_argument("-s", "--size", type=float, help="Bag file size [GB]")
    parser.add_argument("-r", "--repeat_latched", action='store_true', help="Repeat latched messages at beginning of every bag file")

    argcomplete.autocomplete(parser)
    args = parser.parse_args()
    if not (args.size or args.duration):
        print("Either argument --size or --duration is required")
    if args.size and args.size < 0.01:
        args.size = 3
        print("Minimum size is 0.01GB, using default value 3GB")
    if args.duration and args.duration < 1:
        args.duration = 300
        print("Minimum duration is 1s, using default value 300s")
    return args


if __name__ == "__main__":
    args = parse_arguments()

    try:
        bag = rosbag.Bag(args.bag)
    except:
        print("Could not read bag file %s" % args.bag)

    split_duration = args.duration if args.duration else None
    split_size = args.size * 1024**3 if args.size else None
    
    bag_idx = 0
    size = 0
    duration = 0
    t0 = None
    
    latched_msgs = {}  # key: topic + ':::' + callerid, val: [topic, msg, t, header]
    
    success = True
    new_path = os.path.splitext(args.bag)[0] + "_" + str(bag_idx) + os.path.splitext(args.bag)[1]    
    if os.path.exists(new_path):
        print("File '%s' already exists!" % new_path)
        success = False
    else:
        outbag = rosbag.Bag(new_path, 'w')
        print("Writing bag %s" % new_path)

        # Iterate over all messages
        for topic, msg, t, *header in bag.read_messages(raw=True, return_connection_header=args.repeat_latched):            

            if args.repeat_latched:
                # Check if connection is latching
                latching = bool(int(header[0]['latching'].decode('UTF-8')))
                
                # Insert latched msg in dict, one entry for each topic/caller_id pair
                if latching:
                    key = topic + ':::' + header[0]["callerid"].decode('UTF-8')
                    latched_msgs[key] = [topic, msg, t, header]

            # Save time stamp of first message
            if not t0:
                t0 = t
            size += len(msg[1])
            duration = (t - t0).secs

            # Close current bag and open new one
            if args.size and size > split_size or args.duration and duration > split_duration:
                outbag.close()
                bag_idx += 1
                new_path = os.path.splitext(args.bag)[0] + "_" + str(bag_idx) + os.path.splitext(args.bag)[1]
                if os.path.exists(new_path):
                    print("File '%s' already exists!" % new_path)
                    success = False
                    break
                print("Writing bag %s" % new_path)
                t0 = t
                size = 0
                outbag = rosbag.Bag(new_path, 'w')

                # Start each new bag file with copies of all latched messages
                if args.repeat_latched:
                    for l_msg in latched_msgs.values():
                        
                        # Overwrite the original receipt time, otherwise the new bag will have a gap before the new messages start
                        outbag.write(topic=l_msg[0], msg=l_msg[1], t=t0, raw=True)
                
            outbag.write(topic, msg, t, raw=True)
            
    outbag.close()
    if success:        
        print("Done")
        
